{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c1951a7",
   "metadata": {
    "id": "Q65dhunEJWz0"
   },
   "source": [
    "# **Diya**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8716010b",
   "metadata": {
    "id": "1ViTEqlvGaRE"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6f98c82",
   "metadata": {
    "id": "PQ7H-IFLKDI1"
   },
   "outputs": [],
   "source": [
    "df=pd.read_excel(\"Constraint_English_Train.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04bb2e38",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "f-EhSwbkKBFV",
    "outputId": "a64b3a04-9674-4f95-8967-e14bb439c84f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The CDC currently reports 99031 deaths. In gen...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>States reported 1121 deaths a small rise from ...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Politically Correct Woman (Almost) Uses Pandem...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>#IndiaFightsCorona: We have 1524 #COVID testin...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Populous states can generate large case counts...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              tweet label\n",
       "0   1  The CDC currently reports 99031 deaths. In gen...  real\n",
       "1   2  States reported 1121 deaths a small rise from ...  real\n",
       "2   3  Politically Correct Woman (Almost) Uses Pandem...  fake\n",
       "3   4  #IndiaFightsCorona: We have 1524 #COVID testin...  real\n",
       "4   5  Populous states can generate large case counts...  real"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3088f910",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zw6osmDRNLju",
    "outputId": "155f761f-49ef-4217-a659-fe573573adc9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6420, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b11ca126",
   "metadata": {
    "id": "JOdvQhyvNEGs"
   },
   "outputs": [],
   "source": [
    "df1=pd.read_excel(\"english_test_with_labels.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9cd53c35",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B7pzSLhhNPDM",
    "outputId": "3e90ad10-f2c2-4cd4-d9ab-387572768a62"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2140, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae369591",
   "metadata": {
    "id": "ONcTxBhZNdlE"
   },
   "outputs": [],
   "source": [
    "df2=pd.read_excel(\"Constraint_English_Val.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0fe65382",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fjce6IOGNgVf",
    "outputId": "4aa7d1f0-6a79-4412-dbac-33540474294c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2140, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "480b8430",
   "metadata": {
    "id": "ielvOBpENjns"
   },
   "outputs": [],
   "source": [
    "df_combined=pd.concat([df,df1,df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8aa32302",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xrOxz361Nopl",
    "outputId": "db4a1e1c-99cf-445e-dbc8-98d1af2fd162"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10700, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df0ec90e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8KiH7b7EQHUc",
    "outputId": "3af06073-c114-46bd-a096-acf18f2eb6a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10700"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6420+2140+2140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3994bbb2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "jz4FsR_KQL4j",
    "outputId": "687b3391-b042-43bf-9c36-04bf2a460f82"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The CDC currently reports 99031 deaths. In gen...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>States reported 1121 deaths a small rise from ...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Politically Correct Woman (Almost) Uses Pandem...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>#IndiaFightsCorona: We have 1524 #COVID testin...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Populous states can generate large case counts...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              tweet label\n",
       "0   1  The CDC currently reports 99031 deaths. In gen...  real\n",
       "1   2  States reported 1121 deaths a small rise from ...  real\n",
       "2   3  Politically Correct Woman (Almost) Uses Pandem...  fake\n",
       "3   4  #IndiaFightsCorona: We have 1524 #COVID testin...  real\n",
       "4   5  Populous states can generate large case counts...  real"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "31ae4839",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "id": "xQdrkeLJQMOa",
    "outputId": "e4e3746a-6a2a-4515-c3fc-c90f1f69509b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "real    5600\n",
       "fake    5100\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b8dec6c9",
   "metadata": {
    "id": "a5wqenysQMXi"
   },
   "outputs": [],
   "source": [
    "df_combined[\"label\"]=df_combined[\"label\"].apply(lambda x:1 if x==\"real\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "368b316b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "xQz4ne61QMyn",
    "outputId": "42f43d2c-7cb1-431c-e5a5-e9b8584676e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    5600\n",
       "0    5100\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "05e16b41",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6wePjLEZpVzY",
    "outputId": "f13f3289-8a27-4775-bdf3-a786cb474456"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [id, tweet, label]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "nan_values = df_combined.isnull()\n",
    "print(df_combined[nan_values.any(axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5d48b0ba",
   "metadata": {
    "id": "SOh8fPhipnJl"
   },
   "outputs": [],
   "source": [
    "df_combined = df_combined.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "98fb7c8f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "HLQ9CcgwqAcr",
    "outputId": "3b654a28-0e6e-4641-d47f-c901c6608498"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    5600\n",
       "0    5100\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f64fb6a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The CDC currently reports 99031 deaths. In gen...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>States reported 1121 deaths a small rise from ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Politically Correct Woman (Almost) Uses Pandem...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>#IndiaFightsCorona: We have 1524 #COVID testin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Populous states can generate large case counts...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              tweet  label\n",
       "0   1  The CDC currently reports 99031 deaths. In gen...      1\n",
       "1   2  States reported 1121 deaths a small rise from ...      1\n",
       "2   3  Politically Correct Woman (Almost) Uses Pandem...      0\n",
       "3   4  #IndiaFightsCorona: We have 1524 #COVID testin...      1\n",
       "4   5  Populous states can generate large case counts...      1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a5e2c02e",
   "metadata": {
    "id": "Zkb1MijCoj-9"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_combined['tweet'],df_combined['label'], test_size=0.2, random_state=2022, stratify=df_combined['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3676542a",
   "metadata": {
    "id": "UyqVipmJQM_A"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\91935\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.89      1020\n",
      "           1       0.91      0.88      0.89      1120\n",
      "\n",
      "    accuracy                           0.89      2140\n",
      "   macro avg       0.89      0.89      0.89      2140\n",
      "weighted avg       0.89      0.89      0.89      2140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Load pre-trained GloVe vectors\n",
    "def load_glove_model(glove_path):\n",
    "    glove_dict = {}\n",
    "    with open(glove_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], dtype='float32')\n",
    "            glove_dict[word] = vector\n",
    "    return glove_dict\n",
    "\n",
    "# Convert text data into GloVe-based sentence embeddings\n",
    "def get_sentence_embedding(sentence, glove_dict, embedding_dim=100):\n",
    "    words = word_tokenize(sentence.lower())\n",
    "    word_vectors = [glove_dict[word] for word in words if word in glove_dict]\n",
    "    if len(word_vectors) == 0:\n",
    "        return np.zeros(embedding_dim)\n",
    "    return np.mean(word_vectors, axis=0)\n",
    "\n",
    "# Load GloVe vectors\n",
    "glove_path = \"C:/Users/91935/Downloads/glove.6B/glove.6B.50d.txt\"  # Update this path\n",
    "\n",
    "glove_dict = load_glove_model(glove_path)\n",
    "\n",
    "# Convert text data to embeddings\n",
    "X_train_vectorized = np.array([get_sentence_embedding(text, glove_dict) for text in x_train])\n",
    "X_test_vectorized = np.array([get_sentence_embedding(text, glove_dict) for text in x_test])\n",
    "\n",
    "# Train RandomForest model\n",
    "clf = Pipeline([\n",
    "    ('rfc', RandomForestClassifier())\n",
    "])\n",
    "clf.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = clf.predict(X_test_vectorized)\n",
    "print(classification_report(y_test, y_pred))\n",
    "pclfrf = clf.score(X_test_vectorized, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e2eaf53c-a9bf-40e4-8673-66fff820f638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='pclfrf.pkl' target='_blank'>pclfrf.pkl</a><br>"
      ],
      "text/plain": [
       "C:\\Users\\91935\\NLP\\newpkls\\pclfrf.pkl"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(clf, 'pclfrf.pkl')\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Provide a download link\n",
    "FileLink('pclfrf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c0b758f4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8qdJX9b5h2lX",
    "outputId": "b1ceb854-fb60-4fe4-9958-6f74c7f96484"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.84      0.86      1020\n",
      "           1       0.86      0.89      0.87      1120\n",
      "\n",
      "    accuracy                           0.86      2140\n",
      "   macro avg       0.86      0.86      0.86      2140\n",
      "weighted avg       0.86      0.86      0.86      2140\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='pclfsvc.pkl' target='_blank'>pclfsvc.pkl</a><br>"
      ],
      "text/plain": [
       "C:\\Users\\91935\\NLP\\newpkls\\pclfsvc.pkl"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = Pipeline([\n",
    "    ('svc', SVC(kernel='linear'))\n",
    "])\n",
    "clf.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = clf.predict(X_test_vectorized)\n",
    "print(classification_report(y_test, y_pred))\n",
    "pclfsvc = clf.score(X_test_vectorized, y_test)\n",
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(clf, 'pclfsvc.pkl')\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Provide a download link\n",
    "FileLink('pclfsvc.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bb9b8f0e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l8OvbdeLh2uY",
    "outputId": "198be0fb-7e5c-4469-ce55-5caf8b0a871f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.84      0.85      1020\n",
      "           1       0.86      0.89      0.87      1120\n",
      "\n",
      "    accuracy                           0.86      2140\n",
      "   macro avg       0.86      0.86      0.86      2140\n",
      "weighted avg       0.86      0.86      0.86      2140\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='pclflr.pkl' target='_blank'>pclflr.pkl</a><br>"
      ],
      "text/plain": [
       "C:\\Users\\91935\\NLP\\newpkls\\pclflr.pkl"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = Pipeline([\n",
    "    ('logreg', LogisticRegression())\n",
    "])\n",
    "clf.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = clf.predict(X_test_vectorized)\n",
    "print(classification_report(y_test, y_pred))\n",
    "pclflr = clf.score(X_test_vectorized, y_test)\n",
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(clf, 'pclflr.pkl')\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Provide a download link\n",
    "FileLink('pclflr.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c68aef5e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BlQTfeFCh22q",
    "outputId": "8f222fa1-dbf0-4406-af68-4a36ae28a972"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.77      0.85      1020\n",
      "           1       0.82      0.96      0.88      1120\n",
      "\n",
      "    accuracy                           0.87      2140\n",
      "   macro avg       0.88      0.86      0.87      2140\n",
      "weighted avg       0.88      0.87      0.87      2140\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='pclfdt.pkl' target='_blank'>pclfdt.pkl</a><br>"
      ],
      "text/plain": [
       "C:\\Users\\91935\\NLP\\newpkls\\pclfdt.pkl"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = Pipeline([\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=5))\n",
    "])\n",
    "clf.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = clf.predict(X_test_vectorized)\n",
    "print(classification_report(y_test, y_pred))\n",
    "pclfdt = clf.score(X_test_vectorized, y_test)\n",
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(clf, 'pclfdt.pkl')\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Provide a download link\n",
    "FileLink('pclfdt.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "403650f5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "on86Ma4Hh2_0",
    "outputId": "8a516f9e-5bd4-4bf8-fdfa-843a9e343dad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.77      0.77      1020\n",
      "           1       0.79      0.80      0.79      1120\n",
      "\n",
      "    accuracy                           0.78      2140\n",
      "   macro avg       0.78      0.78      0.78      2140\n",
      "weighted avg       0.78      0.78      0.78      2140\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='pclfdt.pkl' target='_blank'>pclfdt.pkl</a><br>"
      ],
      "text/plain": [
       "C:\\Users\\91935\\NLP\\newpkls\\pclfdt.pkl"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = Pipeline([\n",
    "    ('dt', DecisionTreeClassifier())\n",
    "])\n",
    "clf.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = clf.predict(X_test_vectorized)\n",
    "print(classification_report(y_test, y_pred))\n",
    "pclfdt = clf.score(X_test_vectorized, y_test)\n",
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(clf, 'pclfdt.pkl')\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Provide a download link\n",
    "FileLink('pclfdt.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a81231c0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pqCTyv5Bh3IN",
    "outputId": "88c0d20c-161c-43a4-e017-2de2e5d4967a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.86      0.88      1020\n",
      "           1       0.88      0.91      0.90      1120\n",
      "\n",
      "    accuracy                           0.89      2140\n",
      "   macro avg       0.89      0.89      0.89      2140\n",
      "weighted avg       0.89      0.89      0.89      2140\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='pclfgb.pkl' target='_blank'>pclfgb.pkl</a><br>"
      ],
      "text/plain": [
       "C:\\Users\\91935\\NLP\\newpkls\\pclfgb.pkl"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = Pipeline([\n",
    "    ('gb', GradientBoostingClassifier())\n",
    "])\n",
    "clf.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = clf.predict(X_test_vectorized)\n",
    "print(classification_report(y_test, y_pred))\n",
    "pclfgb = clf.score(X_test_vectorized, y_test)\n",
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(clf, 'pclfgb.pkl')\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Provide a download link\n",
    "FileLink('pclfgb.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1681e7e2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DqMpmBOOXMxC",
    "outputId": "36ad7822-ec9c-4811-84d3-b51272e0037a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\91935\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\91935\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\91935\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1090e294",
   "metadata": {
    "id": "0w23ZPF_vsGt"
   },
   "outputs": [],
   "source": [
    "def stemming_text(text):\n",
    "    ps=PorterStemmer()\n",
    "    stop_words=set(stopwords.words('english'))\n",
    "    words=word_tokenize(text.lower())\n",
    "    processed_words=[ps.stem(word) for word in words if word.isalnum() and word not in stop_words]\n",
    "\n",
    "    return \" \".join(processed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "31579c07",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-bZvqWOtvzCM",
    "outputId": "0b48f775-a55e-4a3a-cc1d-24e2cdc56f0f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\91935\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    tokens = word_tokenize(text)\n",
    "    filtered_tokens = [lemmatizer.lemmatize(token) for token in tokens if token.isalnum() and token.lower() not in stop_words]\n",
    "\n",
    "    return \" \".join(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3fb2b0cc",
   "metadata": {
    "id": "FFGUNXO0XNPn"
   },
   "outputs": [],
   "source": [
    "df_combined['stemming_content']=df_combined['tweet'].apply(stemming_text)\n",
    "df_combined['lemmatized_content']=df_combined['tweet'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "42f15ad0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "EpqM1Y6yXNaD",
    "outputId": "d8ad4767-0fe3-468f-8b11-7fc060be8986"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>stemming_content</th>\n",
       "      <th>lemmatized_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The CDC currently reports 99031 deaths. In gen...</td>\n",
       "      <td>1</td>\n",
       "      <td>cdc current report 99031 death gener discrep d...</td>\n",
       "      <td>CDC currently report 99031 death general discr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>States reported 1121 deaths a small rise from ...</td>\n",
       "      <td>1</td>\n",
       "      <td>state report 1121 death small rise last tuesda...</td>\n",
       "      <td>States reported 1121 death small rise last Tue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Politically Correct Woman (Almost) Uses Pandem...</td>\n",
       "      <td>0</td>\n",
       "      <td>polit correct woman almost use pandem excus re...</td>\n",
       "      <td>Politically Correct Woman Almost Uses Pandemic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>#IndiaFightsCorona: We have 1524 #COVID testin...</td>\n",
       "      <td>1</td>\n",
       "      <td>indiafightscorona 1524 covid test laboratori i...</td>\n",
       "      <td>IndiaFightsCorona 1524 COVID testing laborator...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Populous states can generate large case counts...</td>\n",
       "      <td>1</td>\n",
       "      <td>popul state gener larg case count look new cas...</td>\n",
       "      <td>Populous state generate large case count look ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              tweet  label  \\\n",
       "0   1  The CDC currently reports 99031 deaths. In gen...      1   \n",
       "1   2  States reported 1121 deaths a small rise from ...      1   \n",
       "2   3  Politically Correct Woman (Almost) Uses Pandem...      0   \n",
       "3   4  #IndiaFightsCorona: We have 1524 #COVID testin...      1   \n",
       "4   5  Populous states can generate large case counts...      1   \n",
       "\n",
       "                                    stemming_content  \\\n",
       "0  cdc current report 99031 death gener discrep d...   \n",
       "1  state report 1121 death small rise last tuesda...   \n",
       "2  polit correct woman almost use pandem excus re...   \n",
       "3  indiafightscorona 1524 covid test laboratori i...   \n",
       "4  popul state gener larg case count look new cas...   \n",
       "\n",
       "                                  lemmatized_content  \n",
       "0  CDC currently report 99031 death general discr...  \n",
       "1  States reported 1121 death small rise last Tue...  \n",
       "2  Politically Correct Woman Almost Uses Pandemic...  \n",
       "3  IndiaFightsCorona 1524 COVID testing laborator...  \n",
       "4  Populous state generate large case count look ...  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "18efd034",
   "metadata": {
    "id": "z15EMCB9XPdY"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_combined['stemming_content'],df_combined['label'], test_size=0.2, random_state=2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3971b56c",
   "metadata": {
    "id": "tnXc7grsXRcW"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 50 into shape (300,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[98], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mean_embedding\u001b[38;5;241m.\u001b[39mreshape((dim,))  \u001b[38;5;66;03m# ðŸ”¥ Fix: Always return shape (300,)\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# âœ… Now, this will work!\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m X_train_vectorized \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([get_sentence_embedding(text, glove_dict, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m x_train])\n\u001b[0;32m     17\u001b[0m X_test_vectorized \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([get_sentence_embedding(text, glove_dict, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m x_test])\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal X_train shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, X_train_vectorized\u001b[38;5;241m.\u001b[39mshape)  \u001b[38;5;66;03m# (8560, 300)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[98], line 13\u001b[0m, in \u001b[0;36mget_sentence_embedding\u001b[1;34m(sentence, glove_dict, dim)\u001b[0m\n\u001b[0;32m     10\u001b[0m stacked \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack(embeddings)  \u001b[38;5;66;03m# Convert list to array\u001b[39;00m\n\u001b[0;32m     11\u001b[0m mean_embedding \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(stacked, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mean_embedding\u001b[38;5;241m.\u001b[39mreshape((dim,))\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 50 into shape (300,)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_sentence_embedding(sentence, glove_dict, dim=300):\n",
    "    words = sentence.split()\n",
    "    embeddings = [glove_dict[word] for word in words if word in glove_dict]\n",
    "\n",
    "    if not embeddings:\n",
    "        return np.zeros(dim, dtype=np.float32)  # ðŸ”¥ Fix: Always return (300,)\n",
    "\n",
    "    stacked = np.stack(embeddings)  # Convert list to array\n",
    "    mean_embedding = np.mean(stacked, axis=0).astype(np.float32)\n",
    "\n",
    "    return mean_embedding.reshape((dim,))  # ðŸ”¥ Fix: Always return shape (300,)\n",
    "\n",
    "# âœ… Now, this will work!\n",
    "X_train_vectorized = np.array([get_sentence_embedding(text, glove_dict, dim=300) for text in x_train])\n",
    "X_test_vectorized = np.array([get_sentence_embedding(text, glove_dict, dim=300) for text in x_test])\n",
    "\n",
    "print(\"Final X_train shape:\", X_train_vectorized.shape)  # (8560, 300)\n",
    "print(\"Final X_test shape:\", X_test_vectorized.shape)    # (2140, 300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d1ad5b0b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: only length-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[78], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m clf \u001b[38;5;241m=\u001b[39m Pipeline([\n\u001b[0;32m      2\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrfc\u001b[39m\u001b[38;5;124m'\u001b[39m, RandomForestClassifier())\n\u001b[0;32m      3\u001b[0m ])\n\u001b[1;32m----> 4\u001b[0m clf\u001b[38;5;241m.\u001b[39mfit(X_train_vectorized, y_train)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py:660\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    654\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    655\u001b[0m         last_step_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_metadata_for_step(\n\u001b[0;32m    656\u001b[0m             step_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    657\u001b[0m             step_params\u001b[38;5;241m=\u001b[39mrouted_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]],\n\u001b[0;32m    658\u001b[0m             all_params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m    659\u001b[0m         )\n\u001b[1;32m--> 660\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator\u001b[38;5;241m.\u001b[39mfit(Xt, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlast_step_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    662\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:360\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 360\u001b[0m X, y \u001b[38;5;241m=\u001b[39m validate_data(\n\u001b[0;32m    361\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    362\u001b[0m     X,\n\u001b[0;32m    363\u001b[0m     y,\n\u001b[0;32m    364\u001b[0m     multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    365\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    366\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mDTYPE,\n\u001b[0;32m    367\u001b[0m     ensure_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    368\u001b[0m )\n\u001b[0;32m    369\u001b[0m \u001b[38;5;66;03m# _compute_missing_values_in_feature_mask checks if X has missing values and\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;66;03m# will raise an error if the underlying tree base estimator can't handle missing\u001b[39;00m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;66;03m# values. Only the criterion is required to determine if the tree supports\u001b[39;00m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;66;03m# missing values.\u001b[39;00m\n\u001b[0;32m    373\u001b[0m estimator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator)(criterion\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:2961\u001b[0m, in \u001b[0;36mvalidate_data\u001b[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[0;32m   2959\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m   2960\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2961\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m   2962\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m   2964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1370\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1366\u001b[0m     )\n\u001b[0;32m   1368\u001b[0m ensure_all_finite \u001b[38;5;241m=\u001b[39m _deprecate_force_all_finite(force_all_finite, ensure_all_finite)\n\u001b[1;32m-> 1370\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1371\u001b[0m     X,\n\u001b[0;32m   1372\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   1373\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39maccept_large_sparse,\n\u001b[0;32m   1374\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   1375\u001b[0m     order\u001b[38;5;241m=\u001b[39morder,\n\u001b[0;32m   1376\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m   1377\u001b[0m     force_writeable\u001b[38;5;241m=\u001b[39mforce_writeable,\n\u001b[0;32m   1378\u001b[0m     ensure_all_finite\u001b[38;5;241m=\u001b[39mensure_all_finite,\n\u001b[0;32m   1379\u001b[0m     ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[0;32m   1380\u001b[0m     allow_nd\u001b[38;5;241m=\u001b[39mallow_nd,\n\u001b[0;32m   1381\u001b[0m     ensure_min_samples\u001b[38;5;241m=\u001b[39mensure_min_samples,\n\u001b[0;32m   1382\u001b[0m     ensure_min_features\u001b[38;5;241m=\u001b[39mensure_min_features,\n\u001b[0;32m   1383\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m   1384\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1385\u001b[0m )\n\u001b[0;32m   1387\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1389\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1055\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1053\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1054\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1055\u001b[0m         array \u001b[38;5;241m=\u001b[39m _asarray_with_order(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[0;32m   1056\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m   1057\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1058\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m   1059\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:832\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[0;32m    830\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    831\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 832\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39masarray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    834\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    835\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    836\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "#import numpy as np\n",
    "\n",
    "#def get_sentence_embedding(sentence, glove_dict, dim=300):\n",
    "   # words = sentence.split()\n",
    "    #embeddings = [glove_dict[word] for word in words if word in glove_dict]\n",
    "\n",
    "    #if not embeddings:\n",
    "        #return np.zeros(dim)  # Ensure a fixed-length vector if no words are found\n",
    "\n",
    "    #return np.mean(embeddings, axis=0)  # Compute average embedding\n",
    "\n",
    "# Convert text data into fixed-length vectors\n",
    "#X_train_vectorized = np.array([get_sentence_embedding(text, glove_dict) for text in x_train])\n",
    "#X_test_vectorized = np.array([get_sentence_embedding(text, glove_dict) for text in x_test])\n",
    "\n",
    "#clf = Pipeline([\n",
    " #   ('rfc', RandomForestClassifier())\n",
    "#])\n",
    "#clf.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "09ac1df9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: only length-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[152], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(X_test_vectorized)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test, y_pred))\n\u001b[0;32m      3\u001b[0m pclfrfs \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mscore(X_test_vectorized, y_test)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:904\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    884\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    885\u001b[0m \u001b[38;5;124;03m    Predict class for X.\u001b[39;00m\n\u001b[0;32m    886\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;124;03m        The predicted classes.\u001b[39;00m\n\u001b[0;32m    903\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 904\u001b[0m     proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_proba(X)\n\u001b[0;32m    906\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    907\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39margmax(proba, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:946\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    944\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    945\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[1;32m--> 946\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_X_predict(X)\n\u001b[0;32m    948\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m    949\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:638\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    636\u001b[0m     ensure_all_finite \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 638\u001b[0m X \u001b[38;5;241m=\u001b[39m validate_data(\n\u001b[0;32m    639\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    640\u001b[0m     X,\n\u001b[0;32m    641\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mDTYPE,\n\u001b[0;32m    642\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    643\u001b[0m     reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    644\u001b[0m     ensure_all_finite\u001b[38;5;241m=\u001b[39mensure_all_finite,\n\u001b[0;32m    645\u001b[0m )\n\u001b[0;32m    646\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[0;32m    647\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:2944\u001b[0m, in \u001b[0;36mvalidate_data\u001b[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[0;32m   2942\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m   2943\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m-> 2944\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m   2945\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m   2946\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1055\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1053\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1054\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1055\u001b[0m         array \u001b[38;5;241m=\u001b[39m _asarray_with_order(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[0;32m   1056\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m   1057\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1058\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m   1059\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:832\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[0;32m    830\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    831\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 832\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39masarray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    834\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    835\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    836\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test_vectorized)\n",
    "print(classification_report(y_test, y_pred))\n",
    "pclfrfs = clf.score(X_test_vectorized, y_test)\n",
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(clf, 'pclfrfs.pkl')\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Provide a download link\n",
    "FileLink('pclfrfs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9a8521ff",
   "metadata": {
    "id": "amK_cz0wXRwv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.81      0.86      1024\n",
      "           1       0.84      0.93      0.88      1116\n",
      "\n",
      "    accuracy                           0.87      2140\n",
      "   macro avg       0.88      0.87      0.87      2140\n",
      "weighted avg       0.88      0.87      0.87      2140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf=Pipeline([\n",
    "    ('svc',SVC())\n",
    "])\n",
    "clf.fit(X_train_vectorized,y_train)\n",
    "y_pred=clf.predict(X_test_vectorized)\n",
    "print(classification_report(y_test,y_pred))\n",
    "pclfsvcs=clf.score(X_test_vectorized,y_test)\n",
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(clf, 'pclfsvcs.pkl')\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Provide a download link\n",
    "FileLink('pclfsvcs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "38b1a14f",
   "metadata": {
    "id": "X2GP9QZNXSA3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.78      0.81      1024\n",
      "           1       0.81      0.88      0.84      1116\n",
      "\n",
      "    accuracy                           0.83      2140\n",
      "   macro avg       0.83      0.83      0.83      2140\n",
      "weighted avg       0.83      0.83      0.83      2140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf=Pipeline([\n",
    "    ('lr',LogisticRegression())\n",
    "])\n",
    "clf.fit(X_train_vectorized,y_train)\n",
    "y_pred=clf.predict(X_test_vectorized)\n",
    "print(classification_report(y_test,y_pred))\n",
    "pclflrs=clf.score(X_test_vectorized,y_test)\n",
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(clf, 'pclflrs.pkl')\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Provide a download link\n",
    "FileLink('pclflrs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5084c97f",
   "metadata": {
    "id": "G2kveEPuXSOL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.67      0.78      1024\n",
      "           1       0.76      0.96      0.85      1116\n",
      "\n",
      "    accuracy                           0.82      2140\n",
      "   macro avg       0.85      0.81      0.81      2140\n",
      "weighted avg       0.85      0.82      0.82      2140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf=Pipeline([\n",
    "    ('knn',KNeighborsClassifier())\n",
    "])\n",
    "clf.fit(X_train_vectorized,y_train)\n",
    "y_pred=clf.predict(X_test_vectorized)\n",
    "print(classification_report(y_test,y_pred))\n",
    "pclfknns=clf.score(X_test_vectorized,y_test)\n",
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(clf, 'pclfknns.pkl')\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Provide a download link\n",
    "FileLink('pclfknns.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cc45dc15",
   "metadata": {
    "id": "HYbLBpQoXSaY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.71      0.74      1024\n",
      "           1       0.75      0.80      0.77      1116\n",
      "\n",
      "    accuracy                           0.76      2140\n",
      "   macro avg       0.76      0.76      0.76      2140\n",
      "weighted avg       0.76      0.76      0.76      2140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf=Pipeline([\n",
    "    ('dtc',DecisionTreeClassifier())\n",
    "])\n",
    "clf.fit(X_train_vectorized,y_train)\n",
    "y_pred=clf.predict(X_test_vectorized)\n",
    "print(classification_report(y_test,y_pred))\n",
    "pclfdts=clf.score(X_test_vectorized,y_test)\n",
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(clf, 'pclfdts.pkl')\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Provide a download link\n",
    "FileLink('pclfdts.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "07e1c121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.79      0.84      1024\n",
      "           1       0.83      0.91      0.87      1116\n",
      "\n",
      "    accuracy                           0.86      2140\n",
      "   macro avg       0.86      0.85      0.85      2140\n",
      "weighted avg       0.86      0.86      0.85      2140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf=Pipeline([\n",
    "    ('gbc',GradientBoostingClassifier())\n",
    "])\n",
    "clf.fit(X_train_vectorized,y_train)\n",
    "y_pred=clf.predict(X_test_vectorized)\n",
    "print(classification_report(y_test,y_pred))\n",
    "pclfgbs=clf.score(X_test_vectorized,y_test)\n",
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(clf, 'pclfgbs.pkl')\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Provide a download link\n",
    "FileLink('pclfgbs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c2bf1512",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df_combined['lemmatized_content'],df_combined['label'], test_size=0.2, random_state=2022, stratify=df_combined['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1d8f0a74",
   "metadata": {
    "id": "tnXc7grsXRcW"
   },
   "outputs": [],
   "source": [
    "X_train_vectorized = np.array([get_sentence_embedding(text, glove_dict) for text in x_train])\n",
    "X_test_vectorized = np.array([get_sentence_embedding(text, glove_dict) for text in x_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6e666a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.89      1020\n",
      "           1       0.90      0.89      0.89      1120\n",
      "\n",
      "    accuracy                           0.89      2140\n",
      "   macro avg       0.89      0.89      0.89      2140\n",
      "weighted avg       0.89      0.89      0.89      2140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "    ('rfc', RandomForestClassifier())\n",
    "])\n",
    "clf.fit(X_train_vectorized, y_train)\n",
    "y_pred=clf.predict(X_test_vectorized)\n",
    "print(classification_report(y_test,y_pred))\n",
    "pclfrfl=clf.score(X_test_vectorized,y_test)\n",
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(clf, 'pclfrfl.pkl')\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Provide a download link\n",
    "FileLink('pclfrfl.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a10202c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.87      0.90      1020\n",
      "           1       0.89      0.93      0.91      1120\n",
      "\n",
      "    accuracy                           0.91      2140\n",
      "   macro avg       0.91      0.90      0.91      2140\n",
      "weighted avg       0.91      0.91      0.91      2140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf=Pipeline([\n",
    "    ('svc',SVC())\n",
    "])\n",
    "clf.fit(X_train_vectorized,y_train)\n",
    "y_pred=clf.predict(X_test_vectorized)\n",
    "print(classification_report(y_test,y_pred))\n",
    "pclfsvcl=clf.score(X_test_vectorized,y_test)\n",
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(clf, 'pclfsvl.pkl')\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Provide a download link\n",
    "FileLink('pclfsvl.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8b7c9383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.84      0.86      1020\n",
      "           1       0.86      0.90      0.88      1120\n",
      "\n",
      "    accuracy                           0.87      2140\n",
      "   macro avg       0.87      0.87      0.87      2140\n",
      "weighted avg       0.87      0.87      0.87      2140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf=Pipeline([\n",
    "    ('lr',LogisticRegression())\n",
    "])\n",
    "clf.fit(X_train_vectorized,y_train)\n",
    "y_pred=clf.predict(X_test_vectorized)\n",
    "print(classification_report(y_test,y_pred))\n",
    "pclflrl=clf.score(X_test_vectorized,y_test)\n",
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(clf, 'pclflrl.pkl')\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Provide a download link\n",
    "FileLink('pclflrl.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3389d0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.80      0.86      1020\n",
      "           1       0.84      0.95      0.89      1120\n",
      "\n",
      "    accuracy                           0.87      2140\n",
      "   macro avg       0.88      0.87      0.87      2140\n",
      "weighted avg       0.88      0.87      0.87      2140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf=Pipeline([\n",
    "    ('knn',KNeighborsClassifier())\n",
    "])\n",
    "clf.fit(X_train_vectorized,y_train)\n",
    "y_pred=clf.predict(X_test_vectorized)\n",
    "print(classification_report(y_test,y_pred))\n",
    "pclfknnl=clf.score(X_test_vectorized,y_test)\n",
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(clf, 'pclfknnl.pkl')\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Provide a download link\n",
    "FileLink('pclfknnl.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3eed3f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.76      0.77      1020\n",
      "           1       0.79      0.79      0.79      1120\n",
      "\n",
      "    accuracy                           0.78      2140\n",
      "   macro avg       0.78      0.78      0.78      2140\n",
      "weighted avg       0.78      0.78      0.78      2140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf=Pipeline([\n",
    "    ('dtc',DecisionTreeClassifier())\n",
    "])\n",
    "clf.fit(X_train_vectorized,y_train)\n",
    "y_pred=clf.predict(X_test_vectorized)\n",
    "print(classification_report(y_test,y_pred))\n",
    "pclfdtl=clf.score(X_test_vectorized,y_test)\n",
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(clf, 'pclfdtl.pkl')\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Provide a download link\n",
    "FileLink('pclfdtl.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fa5e340b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.86      0.87      1020\n",
      "           1       0.87      0.90      0.89      1120\n",
      "\n",
      "    accuracy                           0.88      2140\n",
      "   macro avg       0.88      0.88      0.88      2140\n",
      "weighted avg       0.88      0.88      0.88      2140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf=Pipeline([\n",
    "    ('gbc',GradientBoostingClassifier())\n",
    "])\n",
    "clf.fit(X_train_vectorized,y_train)\n",
    "y_pred=clf.predict(X_test_vectorized)\n",
    "print(classification_report(y_test,y_pred))\n",
    "pclfgbl=clf.score(X_test_vectorized,y_test)\n",
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(clf, 'pclfgbl.pkl')\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Provide a download link\n",
    "FileLink('pclfgbl.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1938161f",
   "metadata": {
    "id": "CK6txA5GJU2z"
   },
   "source": [
    "# **Praveen**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "0d13f427",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "LiKDMrTHV58u",
    "outputId": "0e978818-9f38-4141-f0af-3348da8734d0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "      <th>create_time</th>\n",
       "      <th>stemming_content</th>\n",
       "      <th>lemmatized_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>From @lindseyvonn: The 90 seconds that changed...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.695917e+09</td>\n",
       "      <td>lindseyvonn 90 second chang life http</td>\n",
       "      <td>lindseyvonn 90 second changed life http</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>The Supreme Court in Biden v. Nebraska has str...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.688054e+09</td>\n",
       "      <td>suprem court biden nebraska struck presid bide...</td>\n",
       "      <td>Supreme Court Biden Nebraska struck President ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>U.S. nerve gas hit our own troops in Iraq: htt...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.427731e+09</td>\n",
       "      <td>nerv ga hit troop iraq http http</td>\n",
       "      <td>nerve gas hit troop Iraq http http</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>The Lockdown Files is the biggest leak of data...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.677514e+09</td>\n",
       "      <td>lockdown file biggest leak data involv govern ...</td>\n",
       "      <td>Lockdown Files biggest leak data involving Gov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>What is impeachment and how does it work? @Pet...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.572451e+09</td>\n",
       "      <td>impeach work petewilliamsnbc explain nbcnewsno...</td>\n",
       "      <td>impeachment work PeteWilliamsNBC explains NBCN...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                            content  label   create_time  \\\n",
       "0   1  From @lindseyvonn: The 90 seconds that changed...      0  1.695917e+09   \n",
       "1   2  The Supreme Court in Biden v. Nebraska has str...      0  1.688054e+09   \n",
       "2   3  U.S. nerve gas hit our own troops in Iraq: htt...      0  1.427731e+09   \n",
       "3   4  The Lockdown Files is the biggest leak of data...      0  1.677514e+09   \n",
       "4   5  What is impeachment and how does it work? @Pet...      0  1.572451e+09   \n",
       "\n",
       "                                    stemming_content  \\\n",
       "0              lindseyvonn 90 second chang life http   \n",
       "1  suprem court biden nebraska struck presid bide...   \n",
       "2                   nerv ga hit troop iraq http http   \n",
       "3  lockdown file biggest leak data involv govern ...   \n",
       "4  impeach work petewilliamsnbc explain nbcnewsno...   \n",
       "\n",
       "                                  lemmatized_content  \n",
       "0            lindseyvonn 90 second changed life http  \n",
       "1  Supreme Court Biden Nebraska struck President ...  \n",
       "2                 nerve gas hit troop Iraq http http  \n",
       "3  Lockdown Files biggest leak data involving Gov...  \n",
       "4  impeachment work PeteWilliamsNBC explains NBCN...  "
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34e5e5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.4 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\asyncio\\windows_events.py\", line 322, in run_forever\n",
      "    super().run_forever()\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\91935\\AppData\\Local\\Temp\\ipykernel_9088\\3923140785.py\", line 1, in <module>\n",
      "    from sklearn.ensemble import RandomForestClassifier\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\site-packages\\sklearn\\__init__.py\", line 73, in <module>\n",
      "    from .base import clone  # noqa: E402\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 19, in <module>\n",
      "    from .utils._estimator_html_repr import _HTMLDocumentationLinkMixin, estimator_html_repr\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\__init__.py\", line 15, in <module>\n",
      "    from ._chunking import gen_batches, gen_even_slices\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_chunking.py\", line 11, in <module>\n",
      "    from ._param_validation import Interval, validate_params\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 17, in <module>\n",
      "    from .validation import _is_arraylike_not_scalar\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 21, in <module>\n",
      "    from ..utils._array_api import _asarray_with_order, _is_numpy_namespace, get_namespace\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 17, in <module>\n",
      "    from .fixes import parse_version\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\fixes.py\", line 20, in <module>\n",
      "    import pandas as pd\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\site-packages\\pandas\\__init__.py\", line 26, in <module>\n",
      "    from pandas.compat import (\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\site-packages\\pandas\\compat\\__init__.py\", line 27, in <module>\n",
      "    from pandas.compat.pyarrow import (\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\site-packages\\pandas\\compat\\pyarrow.py\", line 8, in <module>\n",
      "    import pyarrow as pa\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\site-packages\\pyarrow\\__init__.py\", line 65, in <module>\n",
      "    import pyarrow.lib as _lib\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.2.4 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\core\\_multiarray_umath.py:44\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr_name)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(msg \u001b[38;5;241m+\u001b[39m tb_msg)\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m     46\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mImportError\u001b[0m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.2.4 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.4 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\asyncio\\windows_events.py\", line 322, in run_forever\n",
      "    super().run_forever()\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\91935\\AppData\\Local\\Temp\\ipykernel_9088\\3923140785.py\", line 1, in <module>\n",
      "    from sklearn.ensemble import RandomForestClassifier\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\site-packages\\sklearn\\__init__.py\", line 73, in <module>\n",
      "    from .base import clone  # noqa: E402\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 19, in <module>\n",
      "    from .utils._estimator_html_repr import _HTMLDocumentationLinkMixin, estimator_html_repr\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\__init__.py\", line 15, in <module>\n",
      "    from ._chunking import gen_batches, gen_even_slices\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_chunking.py\", line 11, in <module>\n",
      "    from ._param_validation import Interval, validate_params\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 17, in <module>\n",
      "    from .validation import _is_arraylike_not_scalar\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 21, in <module>\n",
      "    from ..utils._array_api import _asarray_with_order, _is_numpy_namespace, get_namespace\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 17, in <module>\n",
      "    from .fixes import parse_version\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\fixes.py\", line 20, in <module>\n",
      "    import pandas as pd\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\site-packages\\pandas\\__init__.py\", line 49, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\site-packages\\pandas\\core\\api.py\", line 1, in <module>\n",
      "    from pandas._libs import (\n",
      "  File \"C:\\Users\\91935\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\__init__.py\", line 17, in <module>\n",
      "    import pandas._libs.pandas_datetime  # noqa: F401 # isort: skip # type: ignore[reportUnusedImport]\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.2.4 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\core\\_multiarray_umath.py:44\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr_name)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(msg \u001b[38;5;241m+\u001b[39m tb_msg)\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m     46\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mImportError\u001b[0m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.2.4 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91935\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated and will be removed in a future release\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m word_tokenize\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KeyedVectors\n\u001b[0;32m      8\u001b[0m nltk\u001b[38;5;241m.\u001b[39mdownload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpunkt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Load pre-trained Word2Vec model\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\gensim\\__init__.py:11\u001b[0m\n\u001b[0;32m      7\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m4.3.3\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parsing, corpora, matutils, interfaces, models, similarities, utils  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[0;32m     14\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgensim\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m logger\u001b[38;5;241m.\u001b[39mhandlers:  \u001b[38;5;66;03m# To ensure reload() doesn't add another one\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\gensim\\corpora\\__init__.py:6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mThis package contains implementations of various streaming corpus I/O format.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# bring corpus classes directly into package namespace, to save some typing\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindexedcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IndexedCorpus  \u001b[38;5;66;03m# noqa:F401 must appear before the other classes\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmmcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MmCorpus  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbleicorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BleiCorpus  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\gensim\\corpora\\indexedcorpus.py:14\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m interfaces, utils\n\u001b[0;32m     16\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mIndexedCorpus\u001b[39;00m(interfaces\u001b[38;5;241m.\u001b[39mCorpusABC):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\gensim\\interfaces.py:19\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m\"\"\"Basic interfaces used across the whole Gensim package.\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;03mThese interfaces are used for building corpora, model transformation and similarity queries.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m \n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils, matutils\n\u001b[0;32m     22\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCorpusABC\u001b[39;00m(utils\u001b[38;5;241m.\u001b[39mSaveLoad):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\gensim\\matutils.py:1034\u001b[0m\n\u001b[0;32m   1029\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m1.\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mlen\u001b[39m(set1 \u001b[38;5;241m&\u001b[39m set2)) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mfloat\u001b[39m(union_cardinality)\n\u001b[0;32m   1032\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1033\u001b[0m     \u001b[38;5;66;03m# try to load fast, cythonized code if possible\u001b[39;00m\n\u001b[1;32m-> 1034\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_matutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m logsumexp, mean_absolute_difference, dirichlet_expectation\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m   1037\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlogsumexp\u001b[39m(x):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\gensim\\_matutils.pyx:1\u001b[0m, in \u001b[0;36minit gensim._matutils\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import KeyedVectors\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Load pre-trained Word2Vec model\n",
    "def load_word2vec_model(word2vec_path):\n",
    "    return KeyedVectors.load_word2vec_format(word2vec_path, binary=True)\n",
    "\n",
    "# Convert text data into Word2Vec-based sentence embeddings\n",
    "def get_sentence_embedding(sentence, word2vec_model, embedding_dim=100):\n",
    "    words = word_tokenize(sentence.lower())\n",
    "    word_vectors = [word2vec_model[word] for word in words if word in word2vec_model]\n",
    "    if len(word_vectors) == 0:\n",
    "        return np.zeros(embedding_dim)\n",
    "    return np.mean(word_vectors, axis=0)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df['tweet'], df['label'], test_size=0.2, random_state=2022)\n",
    "\n",
    "# Load Word2Vec vectors\n",
    "word2vec_path = \"GoogleNews-vectors-negative300.bin\"  \n",
    "word2vec_model = load_word2vec_model(word2vec_path)\n",
    "\n",
    "# Convert text data to embeddings\n",
    "X_train_vectorized = np.array([get_sentence_embedding(text, word2vec_model, embedding_dim=300) for text in x_train])\n",
    "X_test_vectorized = np.array([get_sentence_embedding(text, word2vec_model, embedding_dim=300) for text in x_test])\n",
    "\n",
    "# Train Random Forest model\n",
    "clf = Pipeline([\n",
    "    ('rf', RandomForestClassifier())\n",
    "])\n",
    "clf.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = clf.predict(X_test_vectorized)\n",
    "print(classification_report(y_test, y_pred))\n",
    "dclfrf = clf.score(X_test_vectorized, y_test)\n",
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(clf, 'dclfrf.pkl')\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Provide a download link\n",
    "FileLink('dclfrf.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4614880d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.95      0.93      0.94       620\n",
      "        real       0.94      0.96      0.95       664\n",
      "\n",
      "    accuracy                           0.95      1284\n",
      "   macro avg       0.95      0.95      0.95      1284\n",
      "weighted avg       0.95      0.95      0.95      1284\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf=Pipeline([\n",
    "    ('svc',SVC())\n",
    "])\n",
    "clf.fit(X_train_vectorized,y_train)\n",
    "y_pred=clf.predict(X_test_vectorized)\n",
    "print(classification_report(y_test,y_pred))\n",
    "dclfsvc=clf.score(X_test_vectorized,y_test)\n",
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(clf, 'dclfsvc.pkl')\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Provide a download link\n",
    "FileLink('dclfsvc.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4d552d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.92      0.90      0.91       620\n",
      "        real       0.91      0.93      0.92       664\n",
      "\n",
      "    accuracy                           0.91      1284\n",
      "   macro avg       0.91      0.91      0.91      1284\n",
      "weighted avg       0.91      0.91      0.91      1284\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf=Pipeline([\n",
    "    ('lr',LogisticRegression())\n",
    "])\n",
    "clf.fit(X_train_vectorized,y_train)\n",
    "y_pred=clf.predict(X_test_vectorized)\n",
    "print(classification_report(y_test,y_pred))\n",
    "dclflr=clf.score(X_test_vectorized,y_test)\n",
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(clf, 'dclflr.pkl')\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Provide a download link\n",
    "FileLink('dclflr.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5f3f360c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.95      0.81      0.88       620\n",
      "        real       0.85      0.96      0.90       664\n",
      "\n",
      "    accuracy                           0.89      1284\n",
      "   macro avg       0.90      0.89      0.89      1284\n",
      "weighted avg       0.90      0.89      0.89      1284\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf=Pipeline([\n",
    "    ('knn',KNeighborsClassifier())\n",
    "])\n",
    "clf.fit(X_train_vectorized,y_train)\n",
    "y_pred=clf.predict(X_test_vectorized)\n",
    "print(classification_report(y_test,y_pred))\n",
    "dclfknn=clf.score(X_test_vectorized,y_test)\n",
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(clf, 'dclfknn.pkl')\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Provide a download link\n",
    "FileLink('dclfknn.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5c8dffdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.80      0.78      0.79       620\n",
      "        real       0.80      0.81      0.81       664\n",
      "\n",
      "    accuracy                           0.80      1284\n",
      "   macro avg       0.80      0.80      0.80      1284\n",
      "weighted avg       0.80      0.80      0.80      1284\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf=Pipeline([\n",
    "    ('dtc',DecisionTreeClassifier())\n",
    "])\n",
    "clf.fit(X_train_vectorized,y_train)\n",
    "y_pred=clf.predict(X_test_vectorized)\n",
    "print(classification_report(y_test,y_pred))\n",
    "dclfdt=clf.score(X_test_vectorized,y_test)\n",
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(clf, 'dclfdt.pkl')\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Provide a download link\n",
    "FileLink('dclfdt.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cb3ab699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.93      0.90      0.92       620\n",
      "        real       0.91      0.93      0.92       664\n",
      "\n",
      "    accuracy                           0.92      1284\n",
      "   macro avg       0.92      0.92      0.92      1284\n",
      "weighted avg       0.92      0.92      0.92      1284\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf=Pipeline([\n",
    "    ('gbc',GradientBoostingClassifier())\n",
    "])\n",
    "clf.fit(X_train_vectorized,y_train)\n",
    "y_pred=clf.predict(X_test_vectorized)\n",
    "print(classification_report(y_test,y_pred))\n",
    "dclfgb=clf.score(X_test_vectorized,y_test)\n",
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(clf, 'dclfgb.pkl')\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Provide a download link\n",
    "FileLink('dclfgb.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e2e74525",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_combined['stemming_content'],df_combined['label'], test_size=0.2, random_state=2022, stratify=df_combined['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6461dcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vectorized = np.array([get_sentence_embedding(text, word2vec_model, embedding_dim=300) for text in x_train])\n",
    "X_test_vectorized = np.array([get_sentence_embedding(text, word2vec_model, embedding_dim=300) for text in x_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d41e1092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.87      1020\n",
      "           1       0.90      0.86      0.88      1120\n",
      "\n",
      "    accuracy                           0.88      2140\n",
      "   macro avg       0.88      0.88      0.88      2140\n",
      "weighted avg       0.88      0.88      0.88      2140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "    ('rfc', RandomForestClassifier())\n",
    "])\n",
    "clf.fit(X_train_vectorized, y_train)\n",
    "y_pred=clf.predict(X_test_vectorized)\n",
    "print(classification_report(y_test,y_pred))\n",
    "dclfrfs=clf.score(X_test_vectorized,y_test)\n",
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(clf, 'dclfrfs.pkl')\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Provide a download link\n",
    "FileLink('dclfrfs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "844e6b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92      1020\n",
      "           1       0.92      0.93      0.92      1120\n",
      "\n",
      "    accuracy                           0.92      2140\n",
      "   macro avg       0.92      0.92      0.92      2140\n",
      "weighted avg       0.92      0.92      0.92      2140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf=Pipeline([\n",
    "    ('svc',SVC())\n",
    "])\n",
    "clf.fit(X_train_vectorized,y_train)\n",
    "y_pred=clf.predict(X_test_vectorized)\n",
    "print(classification_report(y_test,y_pred))\n",
    "dclfsvcs=clf.score(X_test_vectorized,y_test)\n",
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(clf, 'dclfsvcs.pkl')\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Provide a download link\n",
    "FileLink('dclfsvcs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2df40fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.88      0.90      1020\n",
      "           1       0.89      0.92      0.91      1120\n",
      "\n",
      "    accuracy                           0.90      2140\n",
      "   macro avg       0.90      0.90      0.90      2140\n",
      "weighted avg       0.90      0.90      0.90      2140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf=Pipeline([\n",
    "    ('lr',LogisticRegression())\n",
    "])\n",
    "clf.fit(X_train_vectorized,y_train)\n",
    "y_pred=clf.predict(X_test_vectorized)\n",
    "print(classification_report(y_test,y_pred))\n",
    "dclflrs=clf.score(X_test_vectorized,y_test)\n",
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(clf, 'dclflrs.pkl')\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Provide a download link\n",
    "FileLink('dclflrs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "282f12ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.79      0.85      1020\n",
      "           1       0.83      0.94      0.88      1120\n",
      "\n",
      "    accuracy                           0.87      2140\n",
      "   macro avg       0.88      0.87      0.87      2140\n",
      "weighted avg       0.88      0.87      0.87      2140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf=Pipeline([\n",
    "    ('knn',KNeighborsClassifier())\n",
    "])\n",
    "clf.fit(X_train_vectorized,y_train)\n",
    "y_pred=clf.predict(X_test_vectorized)\n",
    "print(classification_report(y_test,y_pred))\n",
    "dclfknns=clf.score(X_test_vectorized,y_test)\n",
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(clf, 'dclfknns.pkl')\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Provide a download link\n",
    "FileLink('dclfknns.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7494c725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.78      0.78      1020\n",
      "           1       0.80      0.80      0.80      1120\n",
      "\n",
      "    accuracy                           0.79      2140\n",
      "   macro avg       0.79      0.79      0.79      2140\n",
      "weighted avg       0.79      0.79      0.79      2140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf=Pipeline([\n",
    "    ('dtc',DecisionTreeClassifier())\n",
    "])\n",
    "clf.fit(X_train_vectorized,y_train)\n",
    "y_pred=clf.predict(X_test_vectorized)\n",
    "print(classification_report(y_test,y_pred))\n",
    "dclfdts=clf.score(X_test_vectorized,y_test)\n",
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(clf, 'dclfdts.pkl')\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Provide a download link\n",
    "FileLink('dclfdts.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f178099a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.86      0.87      1020\n",
      "           1       0.87      0.89      0.88      1120\n",
      "\n",
      "    accuracy                           0.88      2140\n",
      "   macro avg       0.88      0.88      0.88      2140\n",
      "weighted avg       0.88      0.88      0.88      2140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf=Pipeline([\n",
    "    ('gbc',GradientBoostingClassifier())\n",
    "])\n",
    "clf.fit(X_train_vectorized,y_train)\n",
    "y_pred=clf.predict(X_test_vectorized)\n",
    "print(classification_report(y_test,y_pred))\n",
    "dclfgbs=clf.score(X_test_vectorized,y_test)\n",
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(clf, 'dclfgbs.pkl')\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Provide a download link\n",
    "FileLink('dclfgbs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d9af5203",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df_combined['lemmatized_content'],df_combined['label'], test_size=0.2, random_state=2022, stratify=df_combined['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "30273b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vectorized = np.array([get_sentence_embedding(text, word2vec_model, embedding_dim=300) for text in x_train])\n",
    "X_test_vectorized = np.array([get_sentence_embedding(text, word2vec_model, embedding_dim=300) for text in x_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "512db458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89      1020\n",
      "           1       0.91      0.89      0.90      1120\n",
      "\n",
      "    accuracy                           0.89      2140\n",
      "   macro avg       0.89      0.89      0.89      2140\n",
      "weighted avg       0.89      0.89      0.89      2140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "    ('rfc', RandomForestClassifier())\n",
    "])\n",
    "clf.fit(X_train_vectorized, y_train)\n",
    "y_pred=clf.predict(X_test_vectorized)\n",
    "print(classification_report(y_test,y_pred))\n",
    "dclfrfl=clf.score(X_test_vectorized,y_test)\n",
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(clf, 'dclfrfl.pkl')\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Provide a download link\n",
    "FileLink('dclfrfl.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9edc6c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.93      1020\n",
      "           1       0.93      0.94      0.93      1120\n",
      "\n",
      "    accuracy                           0.93      2140\n",
      "   macro avg       0.93      0.93      0.93      2140\n",
      "weighted avg       0.93      0.93      0.93      2140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf=Pipeline([\n",
    "    ('svc',SVC())\n",
    "])\n",
    "clf.fit(X_train_vectorized,y_train)\n",
    "y_pred=clf.predict(X_test_vectorized)\n",
    "print(classification_report(y_test,y_pred))\n",
    "dclfsvcl=clf.score(X_test_vectorized,y_test)\n",
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(clf, 'dclfsvcl.pkl')\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Provide a download link\n",
    "FileLink('dclfsvcl.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b64312d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.88      0.90      1020\n",
      "           1       0.89      0.92      0.91      1120\n",
      "\n",
      "    accuracy                           0.90      2140\n",
      "   macro avg       0.90      0.90      0.90      2140\n",
      "weighted avg       0.90      0.90      0.90      2140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf=Pipeline([\n",
    "    ('lr',LogisticRegression())\n",
    "])\n",
    "clf.fit(X_train_vectorized,y_train)\n",
    "y_pred=clf.predict(X_test_vectorized)\n",
    "print(classification_report(y_test,y_pred))\n",
    "dclflrl=clf.score(X_test_vectorized,y_test)\n",
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(clf, 'dclflrl.pkl')\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Provide a download link\n",
    "FileLink('dclflrl.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "969253d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.79      0.85      1020\n",
      "           1       0.83      0.94      0.88      1120\n",
      "\n",
      "    accuracy                           0.87      2140\n",
      "   macro avg       0.88      0.87      0.87      2140\n",
      "weighted avg       0.88      0.87      0.87      2140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf=Pipeline([\n",
    "    ('knn',KNeighborsClassifier())\n",
    "])\n",
    "clf.fit(X_train_vectorized,y_train)\n",
    "y_pred=clf.predict(X_test_vectorized)\n",
    "print(classification_report(y_test,y_pred))\n",
    "dclfknnl=clf.score(X_test_vectorized,y_test)\n",
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(clf, 'dclfknnl.pkl')\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Provide a download link\n",
    "FileLink('dclfknnl.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "51410ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.78      0.78      1020\n",
      "           1       0.80      0.79      0.80      1120\n",
      "\n",
      "    accuracy                           0.79      2140\n",
      "   macro avg       0.79      0.79      0.79      2140\n",
      "weighted avg       0.79      0.79      0.79      2140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf=Pipeline([\n",
    "    ('dtc',DecisionTreeClassifier())\n",
    "])\n",
    "clf.fit(X_train_vectorized,y_train)\n",
    "y_pred=clf.predict(X_test_vectorized)\n",
    "print(classification_report(y_test,y_pred))\n",
    "dclfdtl=clf.score(X_test_vectorized,y_test)\n",
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(clf, 'dclfdtl.pkl')\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Provide a download link\n",
    "FileLink('dclfdtl.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2e5eeab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.87      0.89      1020\n",
      "           1       0.89      0.91      0.90      1120\n",
      "\n",
      "    accuracy                           0.89      2140\n",
      "   macro avg       0.89      0.89      0.89      2140\n",
      "weighted avg       0.89      0.89      0.89      2140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf=Pipeline([\n",
    "    ('gbc',GradientBoostingClassifier())\n",
    "])\n",
    "clf.fit(X_train_vectorized,y_train)\n",
    "y_pred=clf.predict(X_test_vectorized)\n",
    "print(classification_report(y_test,y_pred))\n",
    "dclfgbl=clf.score(X_test_vectorized,y_test)\n",
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(clf, 'dclfgbl.pkl')\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Provide a download link\n",
    "FileLink('dclfgbl.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231f0a73",
   "metadata": {},
   "source": [
    "# **Ranjith**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958bf575",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6cabc69a-26d9-4f0e-a5dd-1c23ae9c3d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\91935\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94      1020\n",
      "           1       0.96      0.93      0.94      1120\n",
      "\n",
      "    accuracy                           0.94      2140\n",
      "   macro avg       0.94      0.94      0.94      2140\n",
      "weighted avg       0.94      0.94      0.94      2140\n",
      "\n",
      "Random Forest Accuracy: 0.9415887850467289\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='rclfrf.pkl' target='_blank'>rclfrf.pkl</a><br>"
      ],
      "text/plain": [
       "C:\\Users\\91935\\NLP\\new fatstext code\\rclfrf.pkl"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import fasttext\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "\n",
    "# Download NLTK tokenizer\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Load datasets\n",
    "df = pd.read_excel(\"Constraint_English_Train.xlsx\")\n",
    "df1 = pd.read_excel(\"english_test_with_labels.xlsx\")\n",
    "df2 = pd.read_excel(\"Constraint_English_Val.xlsx\")\n",
    "\n",
    "# Combine datasets\n",
    "df_combined = pd.concat([df, df1, df2])\n",
    "\n",
    "# Convert labels to binary (1 = \"real\", 0 = \"fake\")\n",
    "df_combined[\"label\"] = df_combined[\"label\"].apply(lambda x: 1 if x == \"real\" else 0)\n",
    "\n",
    "# Split dataset\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    df_combined['tweet'], df_combined['label'], test_size=0.2, random_state=2022, stratify=df_combined['label']\n",
    ")\n",
    "\n",
    "# Save training data for FastText\n",
    "train_text_file = 'fasttext_train.txt'\n",
    "with open(train_text_file, 'w', encoding='utf-8') as f:\n",
    "    for tweet, label in zip(x_train, y_train):\n",
    "        clean_tweet = str(tweet).replace('\\n', ' ').strip()\n",
    "        f.write(f\"__label__{label} {clean_tweet}\\n\")\n",
    "\n",
    "# Train FastText model\n",
    "fasttext_model = fasttext.train_supervised(input=train_text_file, epoch=25, lr=0.5, wordNgrams=2)\n",
    "\n",
    "# Function to get FastText embeddings\n",
    "def get_sentence_vector(text):\n",
    "    if isinstance(text, str):\n",
    "        text = text.replace('\\n', ' ').strip()\n",
    "    else:\n",
    "        text = \"\"\n",
    "    return fasttext_model.get_sentence_vector(text)\n",
    "\n",
    "# Convert text to FastText embeddings\n",
    "x_train_embeddings = np.array([get_sentence_vector(text) for text in x_train])\n",
    "x_test_embeddings = np.array([get_sentence_vector(text) for text in x_test])\n",
    "\n",
    "# Define and train the classifier\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(x_train_embeddings, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = clf.predict(x_test_embeddings)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Model Accuracy\n",
    "rclfrf = clf.score(x_test_embeddings, y_test)\n",
    "print(\"Random Forest Accuracy:\", rclfrf)\n",
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(clf, 'rclfrf.pkl')\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Provide a download link\n",
    "FileLink('rclfrf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5622e639-8bc2-44f2-bc46-a900c5c18f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94      1020\n",
      "           1       0.96      0.93      0.94      1120\n",
      "\n",
      "    accuracy                           0.94      2140\n",
      "   macro avg       0.94      0.94      0.94      2140\n",
      "weighted avg       0.94      0.94      0.94      2140\n",
      "\n",
      "SVM Accuracy: 0.9415887850467289\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='rclfsvc.pkl' target='_blank'>rclfsvc.pkl</a><br>"
      ],
      "text/plain": [
       "C:\\Users\\91935\\NLP\\new fatstext code\\rclfsvc.pkl"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define & train SVM model\n",
    "clf_svc = SVC(kernel='linear')\n",
    "clf_svc.fit(x_train_embeddings, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = clf_svc.predict(x_test_embeddings)\n",
    "\n",
    "# Print Classification Report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Model Accuracy\n",
    "rclfsvc = clf_svc.score(x_test_embeddings, y_test)\n",
    "print(\"SVM Accuracy:\", rclfsvc)\n",
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(clf, 'rclfsvc.pkl')\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Provide a download link\n",
    "FileLink('rclfsvc.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "99df138f-7abd-4f8b-b26d-69fb27ac376d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94      1020\n",
      "           1       0.95      0.94      0.94      1120\n",
      "\n",
      "    accuracy                           0.94      2140\n",
      "   macro avg       0.94      0.94      0.94      2140\n",
      "weighted avg       0.94      0.94      0.94      2140\n",
      "\n",
      "Logistic Regression Accuracy: 0.9401869158878504\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='rclflr.pkl' target='_blank'>rclflr.pkl</a><br>"
      ],
      "text/plain": [
       "C:\\Users\\91935\\NLP\\new fatstext code\\rclflr.pkl"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define and train Logistic Regression model\n",
    "clf_lr = LogisticRegression()\n",
    "clf_lr.fit(x_train_embeddings, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = clf_lr.predict(x_test_embeddings)\n",
    "\n",
    "# Print Classification Report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Model Accuracy\n",
    "rclflr = clf_lr.score(x_test_embeddings, y_test)\n",
    "print(\"Logistic Regression Accuracy:\", rclflr)\n",
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(clf, 'rclflr.pkl')\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Provide a download link\n",
    "FileLink('rclflr.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "11708167-c051-4dcf-b1c1-e194d951ed7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94      1020\n",
      "           1       0.96      0.93      0.94      1120\n",
      "\n",
      "    accuracy                           0.94      2140\n",
      "   macro avg       0.94      0.94      0.94      2140\n",
      "weighted avg       0.94      0.94      0.94      2140\n",
      "\n",
      "KNN Accuracy: 0.9415887850467289\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Path (<tt>rcfl_knn.pkl</tt>) doesn't exist. It may still be in the process of being generated, or you may have the incorrect path."
      ],
      "text/plain": [
       "C:\\Users\\91935\\NLP\\new fatstext code\\rcfl_knn.pkl"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define and train KNN model\n",
    "clf_knn = KNeighborsClassifier(n_neighbors=5)\n",
    "clf_knn.fit(x_train_embeddings, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = clf_knn.predict(x_test_embeddings)\n",
    "\n",
    "# Print Classification Report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Model Accuracy\n",
    "rclf_knn = clf_knn.score(x_test_embeddings, y_test)\n",
    "print(\"KNN Accuracy:\", rclf_knn)\n",
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(clf, 'rclf_knn.pkl')\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Provide a download link\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f521c13f-30e1-498f-a0bb-ad2aaf77b565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94      1020\n",
      "           1       0.96      0.93      0.94      1120\n",
      "\n",
      "    accuracy                           0.94      2140\n",
      "   macro avg       0.94      0.94      0.94      2140\n",
      "weighted avg       0.94      0.94      0.94      2140\n",
      "\n",
      "Decision Tree Accuracy: 0.9429906542056075\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='rclf_dt.pkl' target='_blank'>rclf_dt.pkl</a><br>"
      ],
      "text/plain": [
       "C:\\Users\\91935\\NLP\\new fatstext code\\rclf_dt.pkl"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define and train Decision Tree model\n",
    "clf_dt = DecisionTreeClassifier()\n",
    "clf_dt.fit(x_train_embeddings, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = clf_dt.predict(x_test_embeddings)\n",
    "\n",
    "# Print Classification Report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Model Accuracy\n",
    "rclf_dt = clf_dt.score(x_test_embeddings, y_test)\n",
    "print(\"Decision Tree Accuracy:\", rclf_dt)\n",
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(clf, 'rclf_dt.pkl')\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Provide a download link\n",
    "FileLink('rclf_dt.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d1fc672e-51ee-477f-9dbc-fba29cc3cbc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94      1020\n",
      "           1       0.95      0.93      0.94      1120\n",
      "\n",
      "    accuracy                           0.94      2140\n",
      "   macro avg       0.94      0.94      0.94      2140\n",
      "weighted avg       0.94      0.94      0.94      2140\n",
      "\n",
      "Gradient Boosting Accuracy: 0.9411214953271028\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='rclfgb.pkl' target='_blank'>rclfgb.pkl</a><br>"
      ],
      "text/plain": [
       "C:\\Users\\91935\\NLP\\new fatstext code\\rclfgb.pkl"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define and train Gradient Boosting model\n",
    "clf_gb = GradientBoostingClassifier()\n",
    "clf_gb.fit(x_train_embeddings, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = clf_gb.predict(x_test_embeddings)\n",
    "\n",
    "# Print Classification Report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Model Accuracy\n",
    "rclfgb = clf_gb.score(x_test_embeddings, y_test)\n",
    "print(\"Gradient Boosting Accuracy:\", rclfgb)\n",
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(clf, 'rclfgb.pkl')\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Provide a download link\n",
    "FileLink('rclfgb.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "702724f4-5225-43ca-9ad7-f86cbab4c2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\91935\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\91935\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import fasttext\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Download necessary nltk resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize stemmer and lemmatizer\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Function for stemming\n",
    "def stem_text(text):\n",
    "    if isinstance(text, str):\n",
    "        words = word_tokenize(text)\n",
    "        return \" \".join([stemmer.stem(word) for word in words])\n",
    "    return \"\"\n",
    "\n",
    "# Function for lemmatization\n",
    "def lemmatize_text(text):\n",
    "    if isinstance(text, str):\n",
    "        words = word_tokenize(text)\n",
    "        return \" \".join([lemmatizer.lemmatize(word) for word in words])\n",
    "    return \"\"\n",
    "\n",
    "# Ensure df_combined exists before running this\n",
    "if \"df_combined\" not in locals():\n",
    "    raise ValueError(\"df_combined is not defined. Please load your dataset.\")\n",
    "\n",
    "# Apply stemming and lemmatization\n",
    "df_combined[\"stemmed_tweet\"] = df_combined[\"tweet\"].apply(stem_text)\n",
    "df_combined[\"lemmatized_tweet\"] = df_combined[\"tweet\"].apply(lemmatize_text)\n",
    "\n",
    "# Split data for stemming\n",
    "x_train_stem, x_test_stem, y_train_stem, y_test_stem = train_test_split(\n",
    "    df_combined['stemmed_tweet'], df_combined['label'], test_size=0.2, random_state=2022, stratify=df_combined['label']\n",
    ")\n",
    "\n",
    "# Split data for lemmatization\n",
    "x_train_lem, x_test_lem, y_train_lem, y_test_lem = train_test_split(\n",
    "    df_combined['lemmatized_tweet'], df_combined['label'], test_size=0.2, random_state=2022, stratify=df_combined['label']\n",
    ")\n",
    "\n",
    "# Save training data for FastText (stemming)\n",
    "with open(\"fasttext_train_stem.txt\", 'w', encoding='utf-8') as f:\n",
    "    for tweet, label in zip(x_train_stem, y_train_stem):\n",
    "        clean_tweet = tweet.replace('\\n', ' ').strip()\n",
    "        f.write(f\"__label__{label} {clean_tweet}\\n\")\n",
    "\n",
    "# Save training data for FastText (lemmatization)\n",
    "with open(\"fasttext_train_lem.txt\", 'w', encoding='utf-8') as f:\n",
    "    for tweet, label in zip(x_train_lem, y_train_lem):\n",
    "        clean_tweet = tweet.replace('\\n', ' ').strip()\n",
    "        f.write(f\"__label__{label} {clean_tweet}\\n\")\n",
    "\n",
    "# Train FastText models\n",
    "fasttext_model_stem = fasttext.train_supervised(input=\"fasttext_train_stem.txt\", epoch=25, lr=0.5, wordNgrams=2)\n",
    "fasttext_model_lem = fasttext.train_supervised(input=\"fasttext_train_lem.txt\", epoch=25, lr=0.5, wordNgrams=2)\n",
    "\n",
    "# Function to get FastText embeddings\n",
    "def get_sentence_vector(text, model):\n",
    "    if isinstance(text, str):\n",
    "        text = text.replace('\\n', ' ').strip()\n",
    "    else:\n",
    "        text = \"\"\n",
    "    return model.get_sentence_vector(text)\n",
    "\n",
    "# Convert text to FastText embeddings (stemming)\n",
    "x_train_stem_embeddings = np.array([get_sentence_vector(text, fasttext_model_stem) for text in x_train_stem])\n",
    "x_test_stem_embeddings = np.array([get_sentence_vector(text, fasttext_model_stem) for text in x_test_stem])\n",
    "\n",
    "# Convert text to FastText embeddings (lemmatization)\n",
    "x_train_lem_embeddings = np.array([get_sentence_vector(text, fasttext_model_lem) for text in x_train_lem])\n",
    "x_test_lem_embeddings = np.array([get_sentence_vector(text, fasttext_model_lem) for text in x_test_lem])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4695ffe7-09a6-457f-8235-19d43bb43eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemming Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1020\n",
      "           1       0.96      0.97      0.96      1120\n",
      "\n",
      "    accuracy                           0.96      2140\n",
      "   macro avg       0.96      0.96      0.96      2140\n",
      "weighted avg       0.96      0.96      0.96      2140\n",
      "\n",
      "Random Forest Accuracy (Stemming): 0.9616822429906542\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='rclfrfs.pkl' target='_blank'>rclfrfs.pkl</a><br>"
      ],
      "text/plain": [
       "C:\\Users\\91935\\NLP\\new fatstext code\\rclfrfs.pkl"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rclfrfs = RandomForestClassifier(random_state=2022)\n",
    "rclfrfs.fit(x_train_stem_embeddings, y_train_stem)\n",
    "y_pred_stem = rclfrfs.predict(x_test_stem_embeddings)\n",
    "print(\"Stemming Model Performance:\")\n",
    "print(classification_report(y_test_stem, y_pred_stem))\n",
    "accuracy_stem = rclfrfs.score(x_test_stem_embeddings, y_test_stem)\n",
    "print(\"Random Forest Accuracy (Stemming):\", accuracy_stem)\n",
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(clf, 'rclfrfs.pkl')\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Provide a download link\n",
    "FileLink('rclfrfs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e0da58e0-dbf5-4aaa-880e-b22654502d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== SVM Performance (Stemming) ====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1020\n",
      "           1       0.96      0.96      0.96      1120\n",
      "\n",
      "    accuracy                           0.96      2140\n",
      "   macro avg       0.96      0.96      0.96      2140\n",
      "weighted avg       0.96      0.96      0.96      2140\n",
      "\n",
      "SUPPORT VECTOR MACHINE (Stemming): 0.9602803738317757\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='rclfsvms.pkl' target='_blank'>rclfsvms.pkl</a><br>"
      ],
      "text/plain": [
       "C:\\Users\\91935\\NLP\\new fatstext code\\rclfsvms.pkl"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rclfsvms = SVC(kernel=\"linear\", random_state=2022)\n",
    "\n",
    "# Train and evaluate SVM on stemming\n",
    "print(\"\\n==== SVM Performance (Stemming) ====\")\n",
    "rclfsvms.fit(x_train_stem_embeddings, y_train_stem)\n",
    "y_pred_stem = rclfsvms.predict(x_test_stem_embeddings)\n",
    "print(classification_report(y_test_stem, y_pred_stem))\n",
    "accuracy_stem = rclfsvms.score(x_test_stem_embeddings, y_test_stem)\n",
    "print(\"SUPPORT VECTOR MACHINE (Stemming):\", accuracy_stem)\n",
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(clf, 'rclfsvms.pkl')\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Provide a download link\n",
    "FileLink('rclfsvms.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "eab42d04-e21c-4570-85f7-348306433f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Logistic Regression Performance (Stemming) ====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96      1020\n",
      "           1       0.96      0.97      0.96      1120\n",
      "\n",
      "    accuracy                           0.96      2140\n",
      "   macro avg       0.96      0.96      0.96      2140\n",
      "weighted avg       0.96      0.96      0.96      2140\n",
      "\n",
      "logistic regression (Stemming): 0.9616822429906542\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='rclflrs.pkl' target='_blank'>rclflrs.pkl</a><br>"
      ],
      "text/plain": [
       "C:\\Users\\91935\\NLP\\new fatstext code\\rclflrs.pkl"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rclflrs = LogisticRegression(max_iter=500, random_state=2022)\n",
    "print(\"\\n==== Logistic Regression Performance (Stemming) ====\")\n",
    "rclflrs.fit(x_train_stem_embeddings, y_train_stem)\n",
    "y_pred_stem = rclflrs.predict(x_test_stem_embeddings)\n",
    "print(classification_report(y_test_stem, y_pred_stem))\n",
    "accuracy_stem = rclflrs.score(x_test_stem_embeddings, y_test_stem)\n",
    "print(\"logistic regression (Stemming):\", accuracy_stem)\n",
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(clf, 'rclflrs.pkl')\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Provide a download link\n",
    "FileLink('rclflrs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "08177fda-3999-470d-813c-2e4ad8e2ed7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== KNN Performance (Stemming) ====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1020\n",
      "           1       0.96      0.96      0.96      1120\n",
      "\n",
      "    accuracy                           0.96      2140\n",
      "   macro avg       0.96      0.96      0.96      2140\n",
      "weighted avg       0.96      0.96      0.96      2140\n",
      "\n",
      "logistic regression (Stemming): 0.9607476635514018\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='rclfknns.pkl' target='_blank'>rclfknns.pkl</a><br>"
      ],
      "text/plain": [
       "C:\\Users\\91935\\NLP\\new fatstext code\\rclfknns.pkl"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rclfknns = KNeighborsClassifier(n_neighbors=5)\n",
    "print(\"\\n==== KNN Performance (Stemming) ====\")\n",
    "rclfknns.fit(x_train_stem_embeddings, y_train_stem)\n",
    "y_pred_stem = rclfknns.predict(x_test_stem_embeddings)\n",
    "print(classification_report(y_test_stem, y_pred_stem))\n",
    "accuracy_stem = rclfknns.score(x_test_stem_embeddings, y_test_stem)\n",
    "print(\"logistic regression (Stemming):\", accuracy_stem)\n",
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(clf, 'rclfknns.pkl')\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Provide a download link\n",
    "FileLink('rclfknns.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f3bc2917-b371-46ff-8c6d-5df2c631e5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Decision Tree Performance (Stemming) ====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1020\n",
      "           1       0.96      0.96      0.96      1120\n",
      "\n",
      "    accuracy                           0.96      2140\n",
      "   macro avg       0.96      0.96      0.96      2140\n",
      "weighted avg       0.96      0.96      0.96      2140\n",
      "\n",
      "decission tree (Stemming): 0.9598130841121495\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='rclfdts.pkl' target='_blank'>rclfdts.pkl</a><br>"
      ],
      "text/plain": [
       "C:\\Users\\91935\\NLP\\new fatstext code\\rclfdts.pkl"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rclfdts = DecisionTreeClassifier(random_state=2022)\n",
    "print(\"\\n==== Decision Tree Performance (Stemming) ====\")\n",
    "rclfdts.fit(x_train_stem_embeddings, y_train_stem)\n",
    "y_pred_stem = rclfdts.predict(x_test_stem_embeddings)\n",
    "print(classification_report(y_test_stem, y_pred_stem))\n",
    "accuracy_stem = rclfdts.score(x_test_stem_embeddings, y_test_stem)\n",
    "print(\"decission tree (Stemming):\", accuracy_stem)\n",
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(clf, 'rclfdts.pkl')\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Provide a download link\n",
    "FileLink('rclfdts.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f52352a8-3927-43ff-9fe4-3e210d671124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Gradient Boosting Performance (Stemming) ====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1020\n",
      "           1       0.96      0.97      0.96      1120\n",
      "\n",
      "    accuracy                           0.96      2140\n",
      "   macro avg       0.96      0.96      0.96      2140\n",
      "weighted avg       0.96      0.96      0.96      2140\n",
      "\n",
      "gradient boosting (Stemming): 0.961214953271028\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='rclfgbs.pkl' target='_blank'>rclfgbs.pkl</a><br>"
      ],
      "text/plain": [
       "C:\\Users\\91935\\NLP\\new fatstext code\\rclfgbs.pkl"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rclfgbs = GradientBoostingClassifier(random_state=2022)\n",
    "print(\"\\n==== Gradient Boosting Performance (Stemming) ====\")\n",
    "rclfgbs.fit(x_train_stem_embeddings, y_train_stem)\n",
    "y_pred_stem = rclfgbs.predict(x_test_stem_embeddings)\n",
    "print(classification_report(y_test_stem, y_pred_stem))\n",
    "accuracy_stem = rclfgbs.score(x_test_stem_embeddings, y_test_stem)\n",
    "print(\"gradient boosting (Stemming):\", accuracy_stem)\n",
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(clf, 'rclfgbs.pkl')\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Provide a download link\n",
    "FileLink('rclfgbs.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3decc9b-c62b-44bb-9c24-c1a4a901185a",
   "metadata": {},
   "source": [
    "#df_combined[\"lemmatized_tweet\"] = df_combined[\"tweet\"].apply(lemmatize_text)\n",
    "#x_train_lem, x_test_lem, y_train_lem, y_test_lem = train_test_split(\n",
    " #   df_combined['lemmatized_tweet'], df_combined['label'], test_size=0.2, random_state=2022, stratify=df_combined['label']\n",
    "#)not usefull lemmatizaton is predefined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "635e9233-d477-45a6-89ec-d0dc5bd62eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatization Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1020\n",
      "           1       0.97      0.97      0.97      1120\n",
      "\n",
      "    accuracy                           0.97      2140\n",
      "   macro avg       0.97      0.97      0.97      2140\n",
      "weighted avg       0.97      0.97      0.97      2140\n",
      "\n",
      "Random Forest Accuracy (Lemmatization): 0.9654205607476636\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='rclfrfl.pkl' target='_blank'>rclfrfl.pkl</a><br>"
      ],
      "text/plain": [
       "C:\\Users\\91935\\NLP\\new fatstext code\\rclfrfl.pkl"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rclfrfl = RandomForestClassifier(random_state=2022)\n",
    "rclfrfl.fit(x_train_lem_embeddings, y_train_lem)\n",
    "y_pred_lem = rclfrfl.predict(x_test_lem_embeddings)\n",
    "print(\"Lemmatization Model Performance:\")\n",
    "print(classification_report(y_test_lem, y_pred_lem))\n",
    "accuracy_lem = rclfrfl.score(x_test_lem_embeddings, y_test_lem)\n",
    "print(\"Random Forest Accuracy (Lemmatization):\", accuracy_lem)\n",
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(clf, 'rclfrfl.pkl')\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Provide a download link\n",
    "FileLink('rclfrfl.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b5eece64-7230-47b1-b35f-b64bb98014b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== SVM Performance (Lemmatization) ====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1020\n",
      "           1       0.97      0.97      0.97      1120\n",
      "\n",
      "    accuracy                           0.97      2140\n",
      "   macro avg       0.97      0.97      0.97      2140\n",
      "weighted avg       0.97      0.97      0.97      2140\n",
      "\n",
      "SVM (Lemmatization): 0.9654205607476636\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='rclfsvml.pkl' target='_blank'>rclfsvml.pkl</a><br>"
      ],
      "text/plain": [
       "C:\\Users\\91935\\NLP\\new fatstext code\\rclfsvml.pkl"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rclfsvml= SVC(kernel=\"linear\", random_state=2022)\n",
    "print(\"\\n==== SVM Performance (Lemmatization) ====\")\n",
    "rclfsvml.fit(x_train_lem_embeddings, y_train_lem)\n",
    "y_pred_lem =rclfsvml.predict(x_test_lem_embeddings)\n",
    "print(classification_report(y_test_lem, y_pred_lem))\n",
    "accuracy_lem = rclfsvml.score(x_test_lem_embeddings, y_test_lem)\n",
    "print(\"SVM (Lemmatization):\", accuracy_lem)\n",
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(clf, 'rclfsvml.pkl')\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Provide a download link\n",
    "FileLink('rclfsvml.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d331df53-4a63-4b13-b248-1095ad2f7ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Logistic Regression Performance (Lemmatization) ====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1020\n",
      "           1       0.96      0.97      0.96      1120\n",
      "\n",
      "    accuracy                           0.96      2140\n",
      "   macro avg       0.96      0.96      0.96      2140\n",
      "weighted avg       0.96      0.96      0.96      2140\n",
      "\n",
      "LogisticRegression (Lemmatization): 0.9630841121495327\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='rclflrl.pkl' target='_blank'>rclflrl.pkl</a><br>"
      ],
      "text/plain": [
       "C:\\Users\\91935\\NLP\\new fatstext code\\rclflrl.pkl"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rclflrl = LogisticRegression(max_iter=500, random_state=2022)\n",
    "print(\"\\n==== Logistic Regression Performance (Lemmatization) ====\")\n",
    "rclflrl.fit(x_train_lem_embeddings, y_train_lem)\n",
    "y_pred_lem = rclflrl.predict(x_test_lem_embeddings)\n",
    "print(classification_report(y_test_lem, y_pred_lem))\n",
    "accuracy_lem = rclflrl.score(x_test_lem_embeddings, y_test_lem)\n",
    "print(\"LogisticRegression (Lemmatization):\", accuracy_lem)\n",
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(clf, 'rclflrl.pkl')\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Provide a download link\n",
    "FileLink('rclflrl.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "36da803c-29ea-4d61-b771-f72ed6547507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== KNN Performance (Lemmatization) ====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1020\n",
      "           1       0.97      0.97      0.97      1120\n",
      "\n",
      "    accuracy                           0.97      2140\n",
      "   macro avg       0.97      0.97      0.97      2140\n",
      "weighted avg       0.97      0.97      0.97      2140\n",
      "\n",
      " KNeighborsClassifie(Lemmatization): 0.9654205607476636\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='rclfcnnl.pkl' target='_blank'>rclfcnnl.pkl</a><br>"
      ],
      "text/plain": [
       "C:\\Users\\91935\\NLP\\new fatstext code\\rclfcnnl.pkl"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rclfcnnl= KNeighborsClassifier(n_neighbors=5)\n",
    "print(\"\\n==== KNN Performance (Lemmatization) ====\")\n",
    "rclfcnnl.fit(x_train_lem_embeddings, y_train_lem)\n",
    "y_pred_lem = rclfcnnl.predict(x_test_lem_embeddings)\n",
    "print(classification_report(y_test_lem, y_pred_lem))\n",
    "accuracy_lem = rclfcnnl.score(x_test_lem_embeddings, y_test_lem)\n",
    "print(\" KNeighborsClassifie(Lemmatization):\", accuracy_lem)\n",
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(clf, 'rclfcnnl.pkl')\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Provide a download link\n",
    "FileLink('rclfcnnl.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c4dc0126-1d35-42ed-bc49-2576569e48cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Decision Tree Performance (Lemmatization) ====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1020\n",
      "           1       0.97      0.97      0.97      1120\n",
      "\n",
      "    accuracy                           0.96      2140\n",
      "   macro avg       0.96      0.96      0.96      2140\n",
      "weighted avg       0.96      0.96      0.96      2140\n",
      "\n",
      "DECISSION TREE (Lemmatization): 0.9644859813084112\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='rclfdtl.pkl' target='_blank'>rclfdtl.pkl</a><br>"
      ],
      "text/plain": [
       "C:\\Users\\91935\\NLP\\new fatstext code\\rclfdtl.pkl"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "rclfdtl= DecisionTreeClassifier(random_state=42)\n",
    "print(\"\\n==== Decision Tree Performance (Lemmatization) ====\")\n",
    "rclfdtl.fit(x_train_lem_embeddings, y_train_lem)\n",
    "y_pred_lem = rclfdtl.predict(x_test_lem_embeddings)\n",
    "print(classification_report(y_test_lem, y_pred_lem))\n",
    "accuracy_lem = rclfdtl.score(x_test_lem_embeddings, y_test_lem)\n",
    "print(\"DECISSION TREE (Lemmatization):\", accuracy_lem)\n",
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(clf, 'rclfdtl.pkl')\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Provide a download link\n",
    "FileLink('rclfdtl.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "12a4d6ed-5dec-46ac-b33d-a3e92058511d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Gradient Boosting Performance (Lemmatization) ====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1020\n",
      "           1       0.97      0.97      0.97      1120\n",
      "\n",
      "    accuracy                           0.97      2140\n",
      "   macro avg       0.97      0.97      0.97      2140\n",
      "weighted avg       0.97      0.97      0.97      2140\n",
      "\n",
      "GRADIENT BOOSTING 0.9654205607476636\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='rclfgbl.pkl' target='_blank'>rclfgbl.pkl</a><br>"
      ],
      "text/plain": [
       "C:\\Users\\91935\\NLP\\new fatstext code\\rclfgbl.pkl"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rclfgbl = GradientBoostingClassifier(random_state=2022)\n",
    "print(\"\\n==== Gradient Boosting Performance (Lemmatization) ====\")\n",
    "rclfgbl.fit(x_train_lem_embeddings, y_train_lem)\n",
    "y_pred_lem = rclfgbl.predict(x_test_lem_embeddings)\n",
    "print(classification_report(y_test_lem, y_pred_lem))\n",
    "accuracy_lem = rclfgbl.score(x_test_lem_embeddings, y_test_lem)\n",
    "print(\"GRADIENT BOOSTING\", accuracy_lem)\n",
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(clf, 'rclfgbl.pkl')\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Provide a download link\n",
    "FileLink('rclfgbl.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c800de17-27b3-4183-857d-925099a81f24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
